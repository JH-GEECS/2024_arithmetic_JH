{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/david3684/2024_arithmetic/src\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "print(os.getcwd())\n",
    "module_path = os.path.abspath(os.path.join('/data2/david3684/2024_arithmetic'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "from src.eval import eval_single_dataset_with_prediction, eval_single_dataset\n",
    "from src.main import save_scale_factors\n",
    "from src.args import parse_arguments\n",
    "from src.datasets.common import get_dataloader, maybe_dictionarize\n",
    "from src.datasets.registry import get_dataset\n",
    "from src.modeling import ImageEncoder, ImageClassifier\n",
    "from src.task_vectors import TaskVector\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.model = 'ViT-L-14'\n",
    "        self.tasks = ['DTD', 'SUN397']\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.task_scale_factors = None\n",
    "        self.save = '/data2/david3684/2024_arithmetic/checkpoints/ViT-L-14'\n",
    "        self.data_location = '/data2/david3684/data'\n",
    "        self.eval_datasets = None\n",
    "        self.train_dataset = None\n",
    "        self.exp_name = None\n",
    "        self.results_db = None\n",
    "        self.batch_size = 128\n",
    "        self.lr = 0.001\n",
    "        self.wd = 0.1\n",
    "        self.ls = 0.0\n",
    "        self.warmup_length = 500\n",
    "        self.epochs = 10\n",
    "        self.load = None\n",
    "        self.cache_dir = None\n",
    "        self.openclip_cachedir = '/data2/david3684/.cache/open_clip'\n",
    "        self.initial_rank_ratio = 1.0\n",
    "        self.low_rank_mode = 'SoRA'\n",
    "        self.pretrained_model = 'openai'\n",
    "        self.scale_shared_weight = False\n",
    "        self.num_test_samples = 2048\n",
    "        self.no_shared_weight = False\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load finetuned weight\n",
    "\n",
    "model_1 = torch.load('/data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/DTD/finetuned.pt').to(args.device)\n",
    "model_2 = torch.load('/data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/SUN397/finetuned.pt').to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_key(old_key):\n",
    "    if old_key.startswith('shared.attn.layer') or old_key.startswith('clip_vit'):\n",
    "        parts = old_key.split('.')\n",
    "        layer_idx = parts[3]\n",
    "        # print(layer_idx)\n",
    "        sub_key = parts[4]\n",
    "        if sub_key in ['q', 'k', 'v']:\n",
    "            return f'model.visual.transformer.resblocks.{layer_idx}.attn.{sub_key}_weight'\n",
    "        elif sub_key == 'out_proj':\n",
    "            return f'model.visual.transformer.resblocks.{layer_idx}.attn.out_proj.weight'\n",
    "        elif sub_key == 'c_fc' or sub_key == 'c_proj':\n",
    "            return f'model.visual.transformer.resblocks.{layer_idx}.mlp.{sub_key}.weight'\n",
    "    return old_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_shared_weight(shared_weight_state_dict, open_clip_state_dict_template):\n",
    "    qkv_store = {}\n",
    "    for old_key, value in shared_weight_state_dict.items():\n",
    "        if 'diff' in old_key or 'scale_dict' in old_key:\n",
    "            continue\n",
    "\n",
    "        new_key = transform_key(old_key)\n",
    "        layer_idx = new_key.split('.')[4]\n",
    "\n",
    "        if layer_idx not in qkv_store:\n",
    "            qkv_store[layer_idx] = {'q': None, 'k': None, 'v': None}\n",
    "\n",
    "        weight_type = new_key.split('.')[-1]\n",
    "        # in_proj.weight (q, k, v)\n",
    "        if weight_type in ['q_weight', 'k_weight', 'v_weight']:\n",
    "            qkv_store[layer_idx][weight_type[0]] = value\n",
    "        else:  # out_proj.weight, c_fc.weight, c_proj.weight\n",
    "            assert new_key in open_clip_state_dict_template\n",
    "            open_clip_state_dict_template[new_key] = value\n",
    "\n",
    "    for layer_idx, qkv in qkv_store.items():\n",
    "        if all(v.bool().all().item() for v in qkv.values()):\n",
    "            in_proj_weight = torch.cat([qkv['q'], qkv['k'], qkv['v']], dim=0)\n",
    "            # concat qkv into 3072*1024 tensor\n",
    "            new_key = f'model.visual.transformer.resblocks.{layer_idx}.attn.in_proj_weight'\n",
    "            assert new_key in open_clip_state_dict_template\n",
    "            open_clip_state_dict_template[new_key] = in_proj_weight\n",
    "        else:\n",
    "            print(\n",
    "                f\"Missing q, k, or v for layer {layer_idx}. q: {qkv['q']}, k: {qkv['k']}, v: {qkv['v']}\")\n",
    "\n",
    "    return open_clip_state_dict_template\n",
    "\n",
    "#나머지 처리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-L-14 pre-trained weights.\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# format shaed weight into openclip state dict\n",
    "shared_weight_state_dict = torch.load('/data2/david3684/2024_arithmetic/shared_weight/20241010_vanilla/rankmin_config_20241010_uni_vanilla_2_v0.bin')\n",
    "zero_shot_encoder = ImageEncoder(args, keep_lang=False)\n",
    "\n",
    "formatted_shared_weight = format_shared_weight(shared_weight_state_dict, zero_shot_encoder.state_dict())\n",
    "\n",
    "print(zero_shot_encoder.load_state_dict(formatted_shared_weight))\n",
    "zero_shot_encoder = zero_shot_encoder.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rank ratio: 0.1\n",
      "Building task vector with shared weight\n",
      "Building task vector with shared weight\n",
      "Evaluate DTD\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:29<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 98.14%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:31<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 96.33%\n",
      "Evaluate SUN397\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:36<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 83.79%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:15<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 81.11%\n",
      "Initial rank ratio: 0.01\n",
      "Building task vector with shared weight\n",
      "Building task vector with shared weight\n",
      "Evaluate DTD\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:32<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 98.19%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:33<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 96.28%\n",
      "Evaluate SUN397\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:22<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 83.46%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:16<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 81.10%\n",
      "Initial rank ratio: 0.001\n",
      "Building task vector with shared weight\n",
      "Building task vector with shared weight\n",
      "Evaluate DTD\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:32<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 98.09%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on DTD exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_DTD_openai.pt\n",
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:29<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on DTD. Accuracy: 96.38%\n",
      "Evaluate SUN397\n",
      "Single task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:17<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 82.64%\n",
      "Multi task model\n",
      "Classification head for ViT-L-14 on SUN397 exists at /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Loading classification head from /data2/david3684/2024_arithmetic/checkpoints/ViT-L-14/head_SUN397_openai.pt\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 21751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [04:15<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done evaluating on SUN397. Accuracy: 81.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loop for task vector rank\n",
    "\n",
    "for initial_rank_ratio in [0.1, 0.01, 0.001]:\n",
    "    args.initial_rank_ratio = initial_rank_ratio\n",
    "    print(f'Initial rank ratio: {initial_rank_ratio}')\n",
    "    low_rank_task_vectors = {}\n",
    "    \n",
    "    # Build low rank task vectors\n",
    "    for task in args.tasks:\n",
    "        model = model_1 if task == 'DTD' else model_2\n",
    "        # eval_single_dataset(model, task, args)\n",
    "        finetuned_state_dict = model_1.state_dict() if task == 'DTD' else model_2.state_dict()\n",
    "        low_rank_task_vectors[task] = TaskVector(args, zero_shot_encoder.state_dict(), finetuned_state_dict, task).to(args.device)\n",
    "    \n",
    "    low_rank_task_vector_sum = sum(low_rank_task_vectors.values())\n",
    "    \n",
    "    for task in args.tasks:\n",
    "        print(f'Evaluate {task}')\n",
    "        # Evaluate sinlge task model\n",
    "        print('Single task model')\n",
    "        low_rank_single_task_encoder = low_rank_task_vectors[task].apply_to(deepcopy(zero_shot_encoder), scaling_coef=1.0)\n",
    "        eval_single_dataset(low_rank_single_task_encoder, task, args)\n",
    "        \n",
    "        # Evaluate multi task model\n",
    "        print('Multi task model')\n",
    "        low_rank_multi_task_encoder = low_rank_task_vector_sum.apply_to(deepcopy(zero_shot_encoder), scaling_coef=1.0)\n",
    "        eval_single_dataset(low_rank_multi_task_encoder, task, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 47\n",
      "Train dataset size: 1880\n",
      "Test dataset size: 1880\n",
      "Downloading and loading the SUN397 dataset...\n",
      "Number of classes: 397\n",
      "Train dataset size: 87003\n",
      "Test dataset size: 2048\n"
     ]
    }
   ],
   "source": [
    "# _, _, val_preprocess = open_clip.create_model_and_transforms(\n",
    "#             args.model, pretrained='openai', cache_dir=args.openclip_cachedir)\n",
    "# dataset_1 = get_dataset(\n",
    "#         args.tasks[0],\n",
    "#         val_preprocess,\n",
    "#         location=args.data_location,\n",
    "#         batch_size=args.batch_size,\n",
    "#         num_workers=16,\n",
    "#         num_test_samples=None,\n",
    "#     )\n",
    "# dataloader_1 = get_dataloader(\n",
    "#     dataset_1, is_train=False, args=args, image_encoder=None)\n",
    "\n",
    "# dataset_2 = get_dataset(\n",
    "#         args.tasks[1],\n",
    "#         val_preprocess,\n",
    "#         location=args.data_location,\n",
    "#         batch_size=args.batch_size,\n",
    "#         num_workers=16,\n",
    "#         num_test_samples=args.num_test_samples,\n",
    "#     )\n",
    "# dataloader_2 = get_dataloader(\n",
    "#     dataset_2, is_train=False, args=args, image_encoder=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
